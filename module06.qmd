# Module 6: LULC Map Generation  {#sec-module-0}

# Module Overview {.unnumbered}

This module provides functionality for users to generate the final LULC map as the primary output product, derived from the validated and optimized classification model developed in Modules 1-5. Before the processing begins, it ensures that all required inputs - such as satellite imagery, classification schemes, and training samples - are properly prepared and validated. Users can specify data splits, select classification modes, perform hyperparameter tuning optimization, and apply the trained model to the entire AOI to produce a high-quality, georeferenced LULC map. The module supports Random Forest (RF) based classification for adaptability, aligning with hierarchical or non-hierarchical schemes from [Module 2](@sec-module-2), and incorporates feedback from optional covariate enhancements in [Module 5](@sec-module-5). Upon completion, users receive a displayable, analyzable, and downloadable map with metadata, enabling applications such as deforestation monitoring or conservation planning.

## Input {.unnumbered}

**User’s Input**

1.  RF hyperparameters: number of trees (`n_tree`), variables per split (`var_split`), minimum leaf population (`min_leaf_pop`).
2.  Choice of hyperparameter tuning option (e.g., Hard Classification Tuning, K-Fold Soft Classification Tuning, etc.).

**Automatic System Input**

1.  None.

**Input from Other Modules**

1.  Near-cloud-free satellite imagery within the AOI ([Module 1](@sec-module-1)).
2.  LULC classification scheme table ([Module 2](@sec-module-2)).
3.  Georeferenced reference data (training + validation samples)([Module 3](@sec-module-3)).
4.  Validated sample data and separability results ([Module 4](@sec-module-4)).

## Output {.unnumbered}

-   Trained RF classification model.
-   Classified LULC raster map.
-   Optimal hyperparameters from tuning process
-   Model accuracy report if validation data available (including overall accuracy, precision, recall, F1-score, Kappa, model error matrix).

## Process {.unnumbered}

```{mermaid}
flowchart TD

%% CHECKING PREREQUISITES
A([<a href="#sec-checking-prerequisites">Check Prerequisites</a>])
B([Prompt Return to Previous Modules if Needed])
C([<a href="#sec-review-inputs">Review Inputs</a>])

A --> B
B --> C

%% MODEL TRAINING AND CLASSIFICATION
D([<a href="#sec-define-classification-specifications">Define Classification Specifications</a>])
E([<a href="#sec-feature-extraction">Feature Extraction</a>])
F([<a href="#sec-train-random-forest-model">Train Random Forest Model</a>])
G([<a href="#sec-model-accuracy-test">Model Accuracy Test</a>])
H([<a href="#sec-classification-apply-model-to-entire-image">Classification</a>])
I([<a href="#sec-review-classification-results">Review Classification Results</a>])
J([<a href="#sec-module-7">Proceed to Module 7</a>])

C --> D
D --> E
E --> F
F --> G
G --> H
H --> I
I -->|Satisfied| J
I -->|Unsatisfied| D   

```

## Checking Prerequisites from Previous Modules {#sec-checking-prerequisites}

**Front-end**

The system verifies all required inputs are available and prompts users to complete previous modules if reference data or other essential inputs are missing.

**Back-end**

1.  Validates availability of satellite imagery, classification scheme, and reference data

2.  Checks reference data partitioning from Module 3

3.  Ensures compatibility between all input datasets

4.  If validation data is unavailable, guides user to Module 3 for completion

## Define Classification Specifications {#sec-define-classification-specifications}

**Front-end**

User configures Random Forest parameters:

-   **Number of trees (n_tree)**: Controls ensemble size (default: 100). More trees increase stability but require more computation.

-   **Variables per split (var_split)**: Features considered at each decision point. Default: square root of total features.

-   **Minimum leaf population (min_leaf_pop)**: Minimum samples in terminal nodes (default: 1). Higher values prevent overfitting.

**Back-end**

1.  Stores user-specified hyperparameters

2.  Prepares for hyperparameter tuning process

3.  Integrates data splitting strategies from FeatureExtraction class

## Hyperparameter Tuning {#sec-hyperparameter-tuning-options}

**Front-end**

User selects a tuning strategy. System evaluates multiple parameter combinations using **training/validation split** from Module 3. Results display optimal parameters and accuracy.

**Back-end**

-   Uses **held-out validation data** to assess performance.

-   If **100% of reference data allocated to training** in Module 3 → **no validation data available** → tuning **disabled**.

-   User must upload **independent validation data in Module 7**.

### Hard Classification Tuning {#sec-hard-classification-tuning}

Uses multiclass classification approach and evaluates performance using overall accuracy metric.

::: callout-tip
## Related Function(s)

`Hard_classification_tuning()` performs grid search for direct multiclass classification, testing all parameter combinations and selecting those with highest accuracy.\
:::

### Soft Classification Tuning {#sec-soft-classification-tuning}

Uses one-vs-rest binary classification approach and evaluates performance using cross-entropy loss.

::: callout-tip
## Related Function(s)

`Soft_classification_tuning()` optimizes parameters for probabilistic classification, selecting combinations with lowest cross-entropy loss.\
:::

### K-Fold Cross Validation {#sec-k-fold-tuning}

**Back-end**

Performs robust parameter optimization using stratified k-fold cross-validation:

-   **Hard K-Fold**: `hard_tuning_kfold()` for multiclass classification with k-fold validation

-   **Soft K-Fold**: `soft_tuning_kfold()` for one-vs-rest classification with k-fold validation

This approach provides more reliable parameter estimates, especially for imbalanced datasets.

## Final Classification {#sec-final-classification}

**Front-end**

User can:

-   Accept **optimal parameters from tuning**

-   Or retain **manual inputs** Progress bars shown during training and map generation.

**Back-end**

Trains the final Random Forest model using optimal parameters identified during tuning:

-   **Bootstrap sampling**: Creates diverse training subsets for each tree

-   **Ensemble construction**: Builds multiple decision trees with variation

-   **Majority voting**: Aggregates predictions across all trees

Users can apply the recommended optimal parameters or use custom values.

### Multiclass Classification {#sec-multiclass-classification}

**Back-end**

Performs direct multiclass classification where each pixel is assigned to a single LULC class.

::: callout-tip
## Related Function(s)

`multiclass_classification()` implements hard classification using the trained Random Forest model to generate the final LULC map.\
:::

### OVR Classification {#sec-ovr-classification}

**Back-end**

Implements One-vs-Rest strategy, generating probability layers for each class and creating final classification via maximum probability.

::: callout-tip
## Related Function(s)

`ovr_classification()` creates probability surfaces for all LULC classes and produces final classification using argmax, providing confidence layers for each class.\
:::

## Review Classification Results {#sec-review-classification-results}

**Front-end**

1.  User examines the generated LULC map and model performance

2.  If satisfied, proceeds to Module 7 for thematic accuracy assessment

3.  If unsatisfied, returns to parameter tuning or previous modules

**Back-end**

1.  Displays optimal parameters and model performance metrics

2.  Provides recommendations for improvement if results are unsatisfactory

3.  Stores trained model and classification results for Module 7

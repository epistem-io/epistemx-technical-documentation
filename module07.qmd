# Module 7: Thematic Accuracy Assessment {#sec-module-0}

# Module Overview {.unnumbered}

This module enables users to perform a thematic accuracy assessment on LULC map generated in [Module 6](@sec-module-6), comparing it against independent validation data to quantitatively evaluate its quality and reliability. It supports verification of prerequisites from Modules 1 to Module 6, allows confirmation or adjustment of data partitions and model configurations, and computes key metrics such as confusion matrices (overall accuracy (OA), Kappa coefficient (κ), producer's accuracy (PA), and user's accuracy (UA). The module provides phased outputs including numerical/visual results, improvement recommendations, and a spatial confidence level map, facilitating iterative refinements for enhanced map accuracy in applications like environmental monitoring or policy planning.

This module focuses on the evaluation and validation of LULC classification results derived from remote sensing data. The objective is to provide users with tools and guidance to assess the reliability of their classified maps and determine their suitability for further analysis. Upon completion, the user will have a validated LULC map and a clear understanding of its accuracy.

## Input {.unnumbered}

**User’s Input**

1.  Upload of test data if not available from [Module 3](@sec-module-3) (shapefile or CSV as per [Module 3](@sec-module-3)).
2.  Button press to initiate accuracy test.

**Automatic System Input**

1.  None.

**Input from Other Modules**

1.  Final land cover map ([Module 6](@sec-module-6)).
2.  Partitioned test samples if available ([Module 3](@sec-module-3)).
3.  Processed satellite imagery ([Module 1](@sec-module-1), if needed for context).

## Output {.unnumbered}

-   Confusion matrix (table).
-   Accuracy metrics: Overall Accuracy (OA), Kappa Coefficient, Producer's Accuracy (PA), User's Accuracy (UA).

## Process

```{mermaid}
flowchart TD

%% CHECKING PREREQUISITES
A([<a href="#sec-checking-prerequisites">Check Prerequisites</a>])
B([Prompt user to complete Module 6 if missing])

A --> B

%% THEMATIC ACCURACY ASSESSMENT
C([<a href="#sec-verify-land-cover-map-availability">Verify Land Cover Map Availability</a>])
D([<a href="#sec-verify-test-data-availability">Verify Test Data Availability</a>])
E([<a href="#sec-upload-and-verify-test-data">Upload and Verify Test Data</a>])
F([<a href="#sec-perform-accuracy-test">Perform Accuracy Test</a>])
G([<a href="#sec-display-and-review-accuracy-results">Display and Review Accuracy Results</a>])

B --> C
C --> D
D -->|Test data available| F
D -->|Test data missing| E
E --> F
F --> G
G -->|Satisfied| H([Process Complete])
G -->|Unsatisfied| B
```

### Checking Prerequisites from Previous Modules

**Front-end**

1.  **Verify Land Cover Map Availability**: The user is notified if the map is missing and prompted to complete [Module 6](https://www.google.com/search?q=%40sec-module-6). 2.  **Verify Validation Data Availability**: If **Validation Data** is available from [Module 3](https://www.google.com/search?q=%40sec-module-3), the user is allowed to proceed. 3.  **Upload and Verify Validation Data**: If missing, the user is prompted to upload a separate **Validation Dataset** and receives verification feedback.

**Back-end**

-   Checks for final land cover map from Module 6

-   Validates availability of independent validation data

-   If prerequisites missing, guides user to complete necessary steps

#### Verify Land Cover Map Availability

**Back-end**

-   Confirms LULC map exists from Module 6

-   If missing, notifies user to complete Module 6 first

#### Verify Validation Data Availability

**Back-end**

-   Checks for validation data from Module 3 partitions

-   If unavailable, provides upload interface for independent validation data

#### Upload and Verify Validation Data

**Back-end**

-   Accepts validation data upload in supported formats

-   Validates data structure and compatibility with classification scheme

-   Provides feedback on upload success or required corrections

### Thematic Accuracy Assessment

#### Perform Accuracy Test

**Back-end**

-   **Spatial Sampling**: Extracts classified values at validation sample locations using `sampleRegions()`

-   **Confusion Matrix**: Generates error matrix using Earth Engine's `errorMatrix()` function

-   **Metric Calculation**: Computes comprehensive accuracy metrics:

    -   **Overall Accuracy (OA)**: Percentage of correctly classified validation samples

    -   **Kappa Coefficient**: Agreement beyond chance, accounting for class distribution

    -   **Producer's Accuracy**: Measure of classification completeness (1 - omission error)

    -   **User's Accuracy**: Measure of classification reliability (1 - commission error)

**Related Functions:**

-   `thematic_assessment()` - performs complete accuracy assessment workflow

#### Display and Review Accuracy Results

**Front-end**

1.  User reviews the test results, including the Confusion Matrix and all accuracy metrics displayed by `print_metrics()`. 2.  If satisfied, the process completes. 3.  If **unsatisfied**, the user is prompted to: \* Go back to @sec-module-3 to check and clarify the **Reference Data**. \* Go back to @sec-module-6 to refine the hyperparameters or try a different classification approach.

**Back-end**

-   Formats and displays comprehensive accuracy report

-   Identifies potential issues based on error patterns

-   Provides specific recommendations for improvement

**Related Functions:**

-   `print_metrics()` - displays formatted accuracy results with interpretations
